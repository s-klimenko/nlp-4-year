{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gensim, logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с моделью\n",
    "\n",
    "Для каких-то своих индивидуальных нужд и экспериментов бывает полезно самому натренировать модель на нужных данных и с нужными параметрами. Но для каких-то общих целей модели уже есть как для русского языка, так и для английского.\n",
    "\n",
    "Модели для русского скачать можно здесь - http://rusvectores.org/ru/models\n",
    "\n",
    "Скачаем модель для русского языка, созданную на основе НКРЯ. Поскольку модели бывают разных форматов, бывает полезно учитывать это в своем скрипте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-05 14:40:54,327 : INFO : loading projection weights from ruscorpora_mean_hs.model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-05 14:41:04,809 : INFO : loaded (281776, 300) matrix from ruscorpora_mean_hs.model.bin\n"
     ]
    }
   ],
   "source": [
    "m = 'ruscorpora_mean_hs.model.bin'\n",
    "if m.endswith('.vec.gz'):\n",
    "    model = gensim.models.Word2Vec.load_word2vec_format(m, binary=False)\n",
    "elif m.endswith('.bin'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "else:\n",
    "    model = gensim.models.Word2Vec.load(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-05 14:41:04,817 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скажем, нам интересны такие слова (пример для русского языка):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new = ['начальник_S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частеречные тэги нужны, поскольку это специфика скачанной модели - она была натренирована на словах, аннотированных их частями речи (и лемматизированных).\n",
    "\n",
    "Попросим у модели 10 ближайших соседей для каждого слова и коэффициент косинусной близости для каждого:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начальник_S\n[ 0.00141657 -0.08540501 -0.01739847  0.04126468 -0.01520346 -0.00201775\n  0.00675521  0.08611108 -0.08708072 -0.08219937]\nзамначальник_S 0.6262379288673401\nзаведующий_S 0.5692601203918457\nкомендант_S 0.5626716017723083\nдежурный_S 0.5406118035316467\nинспектор_S 0.5218732357025146\nшеф_S 0.5208274126052856\nоперуполномоченный_S 0.4978322684764862\nначальство_S 0.4953279197216034\nруководитель_S 0.4885033369064331\nкомандир_S 0.4845768213272095\nразведуправление_S 0.48370814323425293\nделопроизводитель_S 0.48230910301208496\nзаведовать_V 0.479209303855896\nвоенком_S 0.4776104688644409\nгенерал-квартирмейстер_S 0.472171813249588\nполитчасть_S 0.47018593549728394\nводораздельский_A 0.4695557653903961\nполковник_S 0.46777814626693726\nпланово-производственный_A 0.4659891128540039\nсевкавокра_S 0.4646935760974884\n\n\n"
     ]
    }
   ],
   "source": [
    "for word in words_new:\n",
    "    # есть ли слово в модели? Может быть, и нет\n",
    "    if word in model:\n",
    "        print(word)\n",
    "        # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n",
    "        print(model[word][:10])\n",
    "        # выдаем 10 ближайших соседей слова:\n",
    "        for i in model.most_similar(positive=[word], topn=20):\n",
    "            # слово + коэффициент косинусной близости\n",
    "            print(i[0], i[1])\n",
    "        print('\\n')\n",
    "    else:\n",
    "        # Увы!\n",
    "        print(word + ' is not present in the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найди лишнее!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "удивляться_V\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match('говорить_V сказать_V писать_V удивляться_V'.split()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
